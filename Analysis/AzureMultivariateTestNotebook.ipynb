{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import requests\n",
    "import json\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "SUBSCRIPTION_KEY = os.environ[\"ANOMALY_DETECTOR_KEY_WESTEU\"]\n",
    "ANOMALY_DETECTOR_ENDPOINT = os.environ[\"ANOMALY_DETECTOR_ENDPOINT_WESTEU\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Endpoints"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multivariate Anomaly Detection Endpoint\n",
    "\n",
    "`multi-ad-ppe.ppe.cognitiveservices.azure.com/anomalydetector/v1.1-preview`\n",
    "\n",
    "Multivariate Anomaly Detection APIs\n",
    "- List models `[GET] /multivariate/models`\n",
    "- Train a model `[POST] /multivariate/models`\n",
    "- Get a model `[GET] /multivariate/models/{model_id}`\n",
    "- Delete a model `[DELETE] /multivariate/models/{model_id}`\n",
    "- Detect anomalies `[POST] /multivariate/models/{model_id}/detect`\n",
    "- Export a model `[GET] /multivariate/models/{model_id}/export`\n",
    "- Get detection result `[GET] /multivariate/results/{result_id}`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "ENDPOINT = \"multivariante-amp-test-instance-may.cognitiveservices.azure.com/anomalydetector/v1.1-preview\"\n",
    "HEADERS = {\n",
    "    \"Ocp-Apim-Subscription-Key\": SUBSCRIPTION_KEY\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "API_MODEL = \"https://{endpoint}/multivariate/models?$skip=0&$top=5\"\n",
    "API_MODEL_STATUS = \"https://{endpoint}/multivariate/models/{model_id}\"\n",
    "API_MODEL_INFERENCE = \"https://{endpoint}/multivariate/models/{model_id}/detect\"\n",
    "API_RESULTS = \"https://{endpoint}/multivariate/results/{result_id}\"\n",
    "API_EXPORT = \"https://{endpoint}/multivariate/models/{model_id}/export\"\n",
    "API_DELETE = \"https://{endpoint}/multivariate/models/{model_id}\"\n",
    "SOURCE_BLOB_SAS = os.environ[\"SOURCE_BLOB_SAS\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## List Models\n",
    "```http\n",
    "[GET] https://{endpoint}/multivariate/models?$skip=0&$top=5\n",
    "```\n",
    "#### Sample\n",
    " - Request\n",
    "```json\n",
    "header ={\"Content-Type\": \"application/json\", \"Ocp-Apim-Subscription-Key\": \"subscription_key\"}\n",
    "```\n",
    " - Response\n",
    "```json\n",
    "response={\n",
    "  \"models\": [\n",
    "    {\n",
    "        \"createdTime\":\"2020-12-01T09:43:45Z\",\n",
    "        \"displayName\":\"DevOps-Test\",\n",
    "        \"lastUpdatedTime\":\"2020-12-01T09:46:13Z\",\n",
    "        \"modelId\":\"b4c1616c-33b9-11eb-824e-0242ac110002\",\n",
    "        \"status\":\"READY\",\n",
    "        \"variablesCount\":18\n",
    "    },\n",
    "    {\n",
    "        \"createdTime\":\"2020-12-01T09:43:30Z\",\n",
    "        \"displayName\":\"DevOps-Test\",\n",
    "        \"lastUpdatedTime\":\"2020-12-01T09:45:10Z\",\n",
    "        \"modelId\":\"ab9d3e30-33b9-11eb-a3f4-0242ac110002\",\n",
    "        \"status\":\"READY\",\n",
    "        \"variablesCount\":18\n",
    "    },\n",
    "  ],\n",
    "  \"currentCount\": 1, # Current count of trained multivariate models.\n",
    "  \"maxCount\": 50, # Max number of models that can be trained for this subscription.\n",
    "  \"nextLink\": \"string\" # next link to fetch more models\n",
    "}\n",
    "```\n",
    " - Error Response\n",
    " ```json\n",
    "{\n",
    "\"code\": \"string\",\n",
    "\"message\": \"string\"\n",
    "}\n",
    " ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "res = requests.get(API_MODEL.format(endpoint=ENDPOINT), headers=HEADERS)\n",
    "assert res.status_code == 200, f\"Error occured. Error message: {res.content}\"\n",
    "print(res.content)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'{\"models\": [{\"modelId\": \"8d581ca8-bc8d-11eb-a2de-8e75fc066420\", \"createdTime\": \"2021-05-24T12:42:52Z\", \"lastUpdatedTime\": \"2021-05-24T12:46:29Z\", \"status\": \"READY\", \"displayName\": \"TestRequest_6\", \"variablesCount\": 5}, {\"modelId\": \"95793af4-bc8b-11eb-90a1-8e75fc066420\", \"createdTime\": \"2021-05-24T12:28:46Z\", \"lastUpdatedTime\": \"2021-05-24T12:31:40Z\", \"status\": \"READY\", \"displayName\": \"TestRequest_5\", \"variablesCount\": 5}], \"currentCount\": 2, \"maxCount\": 300, \"nextLink\": \"\"}\\n'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model  \n",
    "```HTTP\n",
    "[POST] https://{endpoint}/multivariate/models\n",
    "```\n",
    "- #### Request\n",
    "  - **slidingWindow** An optional field, indicates how many history points will be used to determine the anomaly score of one subsequent point.\n",
    "  - **alignPolicy** An optional field, since those multivariate need to be aligned in the same timestamp before starting the detection.\n",
    "  - **alignMode**, An optional field, indicates how we merge different variables into the same time-range which is required by the model\n",
    "  ```json\n",
    "  {Inner, Outer}\n",
    "  ```\n",
    "  - **fillNAMethod**, optional field, indicates how missed valus will be filled with. Can not be set to *NotFill*, when alignMode is *Outer*\n",
    "  ```json\n",
    "  {Previous, Subsequent, Linear, Zero, Fix, NotFill}\n",
    "  ```\n",
    "  - **paddingValue**, optional field, only be usefull if fillNAMethod is set to *Fix*. \n",
    "  - **source**, required field, source path contain the training zip file.  \n",
    "  ```bash\n",
    "  Source file link of the input variables, each variable will be a csv with two columns, the first column will be timestamp, the second column will be value.Besides these variable csv files, an extra meta.json can be included in th zip file if you would like to rename a variable.Be default, the file name of the variable will be used as the variable name.\",example: \"https://multiadsample.blob.core.windows.net/data/sample_data_2_1000.zip?sp=rl&st=2020-12-04T06:03:47Z&se=2022-12-05T06:03:00Z&sv=2019-12-12&sr=b&sig=AZTbvZ7fcp3MdqGY%2FvGHJXJjUgjS4DneCGl7U5omq5c%3D\"\n",
    "  ```\n",
    "  - **startTime**, require field, it means start time of data you want to use for training, should be %Y-%m-%dT%H:%M:%SZ \n",
    "  format.\n",
    "  - **endTime**, require field, it means end time of data you want to use for training, should be %Y-%m-%dT%H:%M:%SZ format.\n",
    "  - **displayName**, optional field, it means model name.\n",
    "  \n",
    "- #### Response\n",
    "  - model location in headers\n",
    "\n",
    "- #### Sample\n",
    "  - Request\n",
    "  ```json\n",
    "header ={\"Content-Type\": \"application/json\", \"Ocp-Apim-Subscription-Key\": \"subscription_key\"}\n",
    "request=\n",
    "{\n",
    "    \"slidingWindow\": 200,\n",
    "    \"alignPolicy\": {\n",
    "        \"alignMode\": \"Outer\",\n",
    "        \"fillNAMethod\": \"Linear\", \n",
    "        \"paddingValue\": 0\n",
    "    },\n",
    "    \"source\": SOURCE_BLOB_SAS,\n",
    "    \"startTime\": \"2021-01-01T00:00:00Z\", \n",
    "    \"endTime\": \"2021-01-02T12:00:00Z\", \n",
    "    \"displayName\": \"SampleRequest\"\n",
    "}\n",
    "  ```\n",
    "  - Response\n",
    "  ```json\n",
    "  Location:\t{endpoint}/multivariate/models/927e2af8-a657-11ea-8cae-0242ac110002 # GUID\n",
    "  ```\n",
    " - Error Response\n",
    " ```json\n",
    " {\n",
    "   \"code\": \"string\",\n",
    "   \"message\": \"string\"\n",
    " } ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "SLIDING_WINDOW = 200"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data = {\n",
    "    'slidingWindow': SLIDING_WINDOW,\n",
    "    'alignPolicy': {\n",
    "        'alignMode': 'Outer',\n",
    "        'fillNAMethod': 'Linear', \n",
    "        'paddingValue': 0\n",
    "    },\n",
    "    'source': SOURCE_BLOB_SAS,\n",
    "    'startTime': '2020-01-16T00:00:00Z', \n",
    "    'endTime': '2020-02-16T00:00:00Z', \n",
    "    'displayName': 'TestRequest_Final'\n",
    "}\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'slidingWindow': 200,\n",
       " 'alignPolicy': {'alignMode': 'Outer',\n",
       "  'fillNAMethod': 'Linear',\n",
       "  'paddingValue': 0},\n",
       " 'source': 'https://magazyntestampmay2021.blob.core.windows.net/blofortest/DATAPERMINUTE.zip?sp=r&st=2021-05-25T05:30:32Z&se=2021-05-25T13:30:32Z&sv=2020-02-10&sr=b&sig=EdPTxZ8XdcZwj0Ca8YGmDJV94edutLtPtizQSWYE8Ys%3D',\n",
       " 'startTime': '2020-01-16T00:00:00Z',\n",
       " 'endTime': '2020-02-16T00:00:00Z',\n",
       " 'displayName': 'TestRequest_Final'}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "res = requests.post(API_MODEL.format(endpoint=ENDPOINT), data=json.dumps(data), headers=HEADERS)\n",
    "assert res.status_code == 201, f\"Error occured. Error message: {res.content}\"\n",
    "print(res.content)\n",
    "location = res.headers['Location']\n",
    "print(location)\n",
    "model_id = location[location.rindex('/')+1:]\n",
    "print(model_id)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'\"Success\"\\n'\n",
      "https://multivariante-amp-test-instance-may.cognitiveservices.azure.com:443/anomalydetector/v1.1-preview/multivariate/models?$skip=0&$top=5/8f7ba666-bd1a-11eb-acb5-9efb1402586b\n",
      "8f7ba666-bd1a-11eb-acb5-9efb1402586b\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Multivaraite Model Status by modelid\n",
    "```http\n",
    "[GET] https://{endpoint}/multivariate/models/{model_id}\n",
    "```\n",
    "#### Sample\n",
    " - Request\n",
    "```json\n",
    "header ={\"Content-Type\": \"application/json\", \"Ocp-Apim-Subscription-Key\": \"subscription_key\"}\n",
    "```\n",
    " - Response\n",
    " \n",
    "```json\n",
    "response = {\n",
    "    \"createdTime\":\"2020-07-01T07:58:37Z\",\n",
    "    \"lastUpdatedTime\":\"2020-07-01T07:59:55Z\",\n",
    "    \"modelId\":\"ab888466-bb70-11ea-958f-0242ac110002\",\n",
    "    \"modelInfo\":{ # Training Status of the model.\n",
    "        \"diagnoseInfo\":{\n",
    "            \"modelState\":{\n",
    "                \"epochIds\":[10, 20, 30, 40, 50, 60, 70, 80, 90, 100], # 100 epoc in total\n",
    "                \"latenciesInSeconds\":[0.5837657451629639, 0.5688292980194092, 0.5959596633911133, 0.5251538753509521, 0.6021878719329834, 0.6459534168243408, 0.5391685962677002, 0.5622642040252686, 0.5487074851989746, 0.6336326599121094],\n",
    "                \"trainLosses\":[1.682054042816162, 0.7844524383544922, 0.6616984605789185, 0.6293938159942627, 0.6323581337928772, 0.6257774233818054, 0.5985430479049683, 0.6037595868110657, 0.5779791474342346, 0.5583345293998718],\n",
    "                \"validationLosses\":[0.8330008387565613, 0.6937242150306702, 0.7329594492912292, 0.6103720664978027, 0.6125020980834961, 0.5729937553405762, 0.5761528611183167, 0.5710235238075256, 0.5679566264152527, 0.5674979090690613]\n",
    "            },\n",
    "            \"variableStates\":[\n",
    "                { \n",
    "                    \"effectiveCount\":1441,\n",
    "                    \"endTime\":\"2019-04-02T00:00:00Z\",\n",
    "                    \"errors\":[],\n",
    "                    \"filledNARatio\":0.0,\n",
    "                    \"startTime\":\"2019-04-01T00:00:00Z\",\n",
    "                    \"variable\":\"established_connections\"\n",
    "                },\n",
    "                { \n",
    "                    \"effectiveCount\":1441, # Effective time-series points count.\n",
    "                    \"endTime\":\"2019-04-02T00:00:00Z\", # End time of a variable\n",
    "                    \"errors\":[],\n",
    "                    \"filledNARatio\":0.0, # NA ratio of a variable.\n",
    "                    \"startTime\":\"2019-04-01T00:00:00Z\", # Start time of a variable\n",
    "                    \"variable\":\"memory\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"errors\":[], # Error message when creating or training model fails.\n",
    "        \"status\":\"READY\",\n",
    "         \"alignPolicy\":{\n",
    "                \"alignMode\":\"Outer\",\n",
    "                \"fillNAMethod\":\"Linear\",\n",
    "                \"paddingValue\":0\n",
    "         },\n",
    "         \"displayName\":\"DevOps-Test\",\n",
    "         \"endTime\":\"2019-04-02T00:00:00Z\",\n",
    "         \"slidingWindow\":28,\n",
    "         \"source\":\"/data/sample_data.zip\",\n",
    "         \"startTime\":\"2019-04-01T00:00:00Z\"\n",
    "    }\n",
    "}\n",
    "  \n",
    "```\n",
    " - Error Response\n",
    " ```json\n",
    "{\n",
    "\"code\": \"string\",\n",
    "\"message\": \"string\"\n",
    "}\n",
    " ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "res = requests.get(API_MODEL_STATUS.format(endpoint=ENDPOINT, model_id = model_id), headers=HEADERS)\n",
    "assert res.status_code == 200, f\"Error occured. Error message: {res.content}\"\n",
    "res_content = json.loads(res.content)\n",
    "#print(json.dumps(res_content))\n",
    "print(res_content['modelInfo']['status'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "READY\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detection with the trained model\n",
    "```http\n",
    "[POST] https://{endpoint}/multivariate/models/{model_id}/detect\n",
    "```\n",
    "inference api will return an resultid, you can get result by get inference result api.\n",
    "\n",
    "- #### Request\n",
    "   - **source**, required field, source path contain the training zip file.\n",
    "```json\n",
    " Source file link of the input variables, each variable will be a csv with two columns, the first column will be timestamp, the second column will be value.Besides these variable csv files, an extra meta.json can be included in th zip file if you would like to rename a variable.Be default, the file name of the variable will be used as the variable name.\",example: \"https://multiadsample.blob.core.windows.net/data/sample_data_2_1000.zip?sp=rl&st=2020-12-04T06:03:47Z&se=2022-12-05T06:03:00Z&sv=2019-12-12&sr=b&sig=AZTbvZ7fcp3MdqGY%2FvGHJXJjUgjS4DneCGl7U5omq5c%3D\"\n",
    "```\n",
    "   - **startTime**, a require field, it means start time of data you want to use to inference, should be %Y-%m-%dT%H:%M:%SZ format. \n",
    "   - **endTime**, a require field, it means end time of data you want to use to inference, should be %Y-%m-%dT%H:%M:%SZ format.  \n",
    "\n",
    "- #### Response\n",
    "  - result location in headers\n",
    "  \n",
    "- #### Sample  \n",
    "- Request\n",
    "\n",
    "```json\n",
    "header ={\"Content-Type\": \"application/json\", \"Ocp-Apim-Subscription-Key\": \"subscription_key\"}\n",
    "request={\n",
    "  \"source\": SOURCE_BLOB_SAS,\n",
    "  \"startTime\": \"2020-01-01T00:00:00Z\",\n",
    "  \"endTime\": \"2020-02-01T00:00:00Z\"\n",
    "}\n",
    "```\n",
    "- Response\n",
    "```json\n",
    "Location:    {endpoint}/multivariate/results/927e2af8-a657-11ea-8cae-0242ac110002 # GUID\n",
    " ```\n",
    "- Error Response\n",
    " ```json\n",
    "{\n",
    "\"code\": \"string\",\n",
    "\"message\": \"string\"\n",
    "}\n",
    " ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "data = {\n",
    "    'source': SOURCE_BLOB_SAS,\n",
    "    'startTime': '2020-08-25T00:00:00Z', \n",
    "    'endTime': '2020-09-28T00:00:00Z', \n",
    "}\n",
    "\n",
    "res = requests.post(API_MODEL_INFERENCE.format(endpoint=ENDPOINT, model_id=model_id), \n",
    "                    data=json.dumps(data), headers=HEADERS)\n",
    "assert res.status_code == 201, f\"Error occured. Error message: {res.content}\"\n",
    "print(res.content)\n",
    "result_id = res.headers['location'].split(\"/\")[-1]\n",
    "print(f\"result id = {result_id}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'\"Success\"\\n'\n",
      "result id = 27932f10-bd24-11eb-a16f-faed18866e16\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Detection Result\n",
    "```http\n",
    "[GET] https://{endpoint}/multivariate/results/{result_id}\n",
    "```\n",
    "- #### Sample\n",
    "- Request\n",
    "```json\n",
    "header ={\"Content-Type\": \"application/json\", \"Ocp-Apim-Subscription-Key\": \"subscription_key\"}\n",
    "```\n",
    "- Response\n",
    "```json\n",
    "Response={\n",
    "  \"resultId\": \"45aad126-aafd-11ea-b8fb-d89ef3400c5f\",\n",
    "  \"summary\": {\n",
    "    \"status\": \"READY\", # Multivariate anomaly detection status\n",
    "    \"errors\": [ # Error message when inference fails.\n",
    "      {\n",
    "        \"code\": \"string\",\n",
    "        \"message\": \"string\"\n",
    "      }\n",
    "    ],\n",
    "    \"variableStates\": [\n",
    "      {\n",
    "        \"variable\": \"ad_input\",\n",
    "        \"filledNARatio\": 0,\n",
    "        \"effectiveCount\": 26,\n",
    "        \"startTime\": \"2019-04-01T00:00:00Z\",\n",
    "        \"endTime\": \"2019-04-01T00:25:00Z\",\n",
    "        \"errors\": []\n",
    "      },\n",
    "      {\n",
    "        \"variable\": \"ad_ontimer_output\",\n",
    "        \"filledNARatio\": 0,\n",
    "        \"effectiveCount\": 26,\n",
    "        \"startTime\": \"2019-04-01T00:00:00Z\",\n",
    "        \"endTime\": \"2019-04-01T00:25:00Z\",\n",
    "        \"errors\": []\n",
    "      }\n",
    "    ],\n",
    "    \"setupInfo\": {\n",
    "      \"source\": \"/data/{$zipfile_name}\",\n",
    "      \"startTime\": \"2019-04-01T00:15:00Z\",\n",
    "      \"endTime\": \"2019-04-01T00:40:00Z\"\n",
    "    }\n",
    "  },\n",
    "  \"results\": [\n",
    "    {\n",
    "      \"timestamp\": \"2019-04-01T00:19:00Z\",\n",
    "      \"errors\": [\n",
    "        {\n",
    "          \"code\": \"InsufficientHistoricalData\",\n",
    "          \"message\": \"historical data is not enough.\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"timestamp\": \"2019-04-01T00:20:00Z\",\n",
    "      \"value\":{\n",
    "          \"contributors\": [],# isAnomaly is false, contributors is empty.\n",
    "          \"isAnomaly\": false,\n",
    "          \"severity\": 0.3509107994398884,\n",
    "          \"score\": 0.34231\n",
    "      },\n",
    "      \"errors\": []\n",
    "    },\n",
    "    {\n",
    "      \"timestamp\": \"2019-04-01T00:21:00Z\",\n",
    "      \"value\":{\n",
    "          \"contributors\": [\n",
    "          {\n",
    "              \"contributionScore\": 0.0007775013367514271, # The higher the contributionScore is, the more likely the contributor to be the root cause of a anomaly.\n",
    "              \"variable\": \"ad_ontimer_output\" # Variable name of a contributor\n",
    "          },\n",
    "          {\n",
    "              \"contributionScore\": 0.0007989604079048129,\n",
    "              \"variable\": \"ad_input\"\n",
    "          }\n",
    "        ],\n",
    "          \"isAnomaly\": true, # To indicate whether current timestamp is anomaly or not\n",
    "          \"severity\": 0.42135109874230336, # severity of the current timestamp, the more significant an anomaly is, the higher the severity will be\n",
    "          \"score\": 0.23485905670108112\n",
    "      },\n",
    "      \"errors\": []\n",
    "    }\n",
    "   ]\n",
    "}\n",
    "```\n",
    " - Error Response\n",
    " ```json\n",
    "{\n",
    "\"code\": \"string\",\n",
    "\"message\": \"string\"\n",
    "}\n",
    " ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "res = requests.get(API_RESULTS.format(endpoint=ENDPOINT, result_id=result_id), headers=HEADERS)\n",
    "assert res.status_code == 200, f\"Error occured. Error message: {res.content}\"\n",
    "print(res.content)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'{\"resultId\": \"27932f10-bd24-11eb-a16f-faed18866e16\", \"summary\": {\"status\": \"FAILED\", \"errors\": [{\"code\": \"DataExceedsLimit\", \"message\": \"The length of data whose timestamp is between startTime and endTime exceeds limit(2880).\"}], \"variableStates\": [{\"variable\": \"T1_przMieszGrudk2\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_podc-komora26L\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa2_F562t_przeplyw_oleju_w_lozysku_C\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_wydWaga3\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_temp-komora17P\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_wydWaga7\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa1_Z555tD_drgania_lozyskaD\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_podc-komora22L\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"Ssawa2_Podcisnienie_przed_ssawa\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_podc-komora23P\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_temp-komora22L\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa2_T480t7_temp_wody_chlodz_zasil\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_WT15_ruda_wydajnosc\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_wydWaga1\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa1_F563_2t_przep_ol_w_lozA_si\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_TempSpiekuzaChlodnia\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_Temperatura_PT128\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa2_T480t2_temp_w_loz_B_silnika\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa1_Z555tC_drgania_lozyskaC\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_przWodyGrud2\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_temp-komora13L\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_podc-komora17P\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_podc-komora7L\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa2_Otwarcie_klapy\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_temp-komora5L\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa2_P556a_cis_oleju_w_obiegu\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_wydWaga6\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa1_T480t3_temp_pow_chlsilwlot\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"ssawa1_T480t5_temp_pow_chlsilwylo\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}, {\"variable\": \"T1_OCtprzeplpow\", \"filledNARatio\": 0.0, \"effectiveCount\": 48961, \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\", \"errors\": []}], \"setupInfo\": {\"source\": \"https://magazyntestampmay2021.blob.core.windows.net/blofortest/DATAPERMINUTE.zip?sp=r&st=2021-05-25T05:30:32Z&se=2021-05-25T13:30:32Z&sv=2020-02-10&sr=b&sig=EdPTxZ8XdcZwj0Ca8YGmDJV94edutLtPtizQSWYE8Ys%3D\", \"startTime\": \"2020-08-25T00:00:00Z\", \"endTime\": \"2020-09-28T00:00:00Z\"}}, \"results\": []}\\n'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "\n",
    "raw_result = json.loads(requests.get(API_RESULTS.format(endpoint=ENDPOINT, result_id=result_id), headers=HEADERS).content)\n",
    "if raw_result['summary']['status'] != 'READY':\n",
    "    print(\"result not ready\")\n",
    "\n",
    "filter_item = list(filter(lambda x: 'value' in x and 'isAnomaly' in x['value'] and x['timestamp'] >= start and x['timestamp'] <= end, raw_result['results']))\n",
    "\n",
    "timestamps = [item['timestamp'] for item in filter_item]\n",
    "isAnomaly = [item['value']['isAnomaly'] for item in filter_item]\n",
    "RawScore = [item['value']['score'] for item in filter_item]\n",
    "Severity = [item['value']['severity'] for item in filter_item]\n",
    "result = pd.DataFrame({'Timestamp': timestamps, 'isAnomaly': isAnomaly, 'RawScore': RawScore, 'Severity': Severity})"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "result not ready\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize Results\n",
    "Demo code to draw results. Additional python package is required."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from bokeh.io import output_file, show, output_notebook, save\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure\n",
    "from matplotlib import pyplot\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools  \n",
    "import shutil\n",
    "import uuid\n",
    "import zipfile\n",
    "from urllib.request import urlretrieve\n",
    "%matplotlib inline\n",
    "output_notebook()\n",
    "\n",
    "def unzip_file(zip_src, dst_dir):\n",
    "    r = zipfile.is_zipfile(zip_src)\n",
    "    if r:\n",
    "        fz = zipfile.ZipFile(zip_src, 'r')\n",
    "        print(fz)\n",
    "        for file in fz.namelist():\n",
    "            fz.extract(file, dst_dir)\n",
    "    else:\n",
    "        print('This is not zip')\n",
    "        \n",
    "def load_data(local_data_path, start, end):\n",
    "    new_dir = os.path.join('.', str(uuid.uuid1()))\n",
    "    shutil.rmtree(new_dir, ignore_errors=True)\n",
    "    os.mkdir(new_dir)\n",
    "    unzip_file(local_data_path, new_dir)\n",
    "    files = os.listdir(new_dir)\n",
    "    frames = []\n",
    "    for file in files:\n",
    "        if file[-4:] != '.csv':\n",
    "            continue\n",
    "        frame = pd.read_csv('{}\\\\{}'.format(new_dir, file))\n",
    "        var = file[:file.find('.csv')]\n",
    "        frame = frame.rename(columns={'value': var})\n",
    "        frame = frame[frame['timestamp'] >= start]\n",
    "        frame = frame[frame['timestamp'] <= end]\n",
    "        frame['timestamp'] = pd.to_datetime(frame['timestamp'])\n",
    "        frame.set_index(['timestamp'], inplace=True)\n",
    "        frames.append(frame)\n",
    "    shutil.rmtree(new_dir, ignore_errors=True)\n",
    "    return frames\n",
    "\n",
    "\n",
    "def plot_lines_multi(x, y, p, color, name, t_str=\"hover,save,pan,box_zoom,reset,wheel_zoom\", t_loc='above'):\n",
    "    '''...\n",
    "    '''\n",
    "    p.line(x, y, color=color, legend_label=name)\n",
    "\n",
    "def draw(data_source, local_data_path, result_id, sensitivity, start, end):\n",
    "    urlretrieve(data_source, local_data_path)\n",
    "    print(local_data_path, result_id, sensitivity, start, end)\n",
    "    series = load_data(local_data_path, start, end)\n",
    "    p_list = []\n",
    "    colors = itertools.cycle(palette)\n",
    "    # p_value = figure(background_fill_color=\"#fafafa\", x_axis_type=\"datetime\")\n",
    "    for var, color in zip(series, colors):\n",
    "        name = var.columns.values[0]\n",
    "        p_value = figure(background_fill_color=\"#fafafa\", x_axis_type=\"datetime\")\n",
    "        plot_lines_multi(var.index, var[name], p_value, color, name)\n",
    "        p_list.append(p_value)\n",
    "    header = HEADERS\n",
    "    raw_result = json.loads(requests.get(API_RESULTS.format(endpoint=ENDPOINT, result_id=result_id), headers=header).content)\n",
    "    if raw_result['summary']['status'] != 'READY':\n",
    "        print(\"result not ready\")\n",
    "        return\n",
    "    filter_item = list(filter(lambda x: 'value' in x and 'isAnomaly' in x['value'] and x['timestamp'] >= start and x['timestamp'] <= end, raw_result['results']))\n",
    "    timestamps = [item['timestamp'] for item in filter_item]\n",
    "    isAnomaly = [item['value']['isAnomaly'] for item in filter_item]\n",
    "    RawScore = [item['value']['score'] for item in filter_item]\n",
    "    Severity = [item['value']['severity'] for item in filter_item]\n",
    "    result = pd.DataFrame({'Timestamp': timestamps, 'isAnomaly': isAnomaly, 'RawScore': RawScore, 'Severity': Severity})\n",
    "    result.loc[(result.Severity <= (1 - sensitivity)) & (result.isAnomaly == True), 'isAnomaly'] = False\n",
    "    result['Timestamp'] = pd.to_datetime(result['Timestamp'])\n",
    "    result.set_index(['Timestamp'], inplace=True)\n",
    "    result = result.reindex(['isAnomaly', 'RawScore', 'Severity'], axis=1)\n",
    "    colors = ['red', 'blue', 'black']\n",
    "    for col, color in zip(result.columns, colors):\n",
    "        p = figure(background_fill_color=\"#fafafa\", x_axis_type=\"datetime\")\n",
    "        p.line(result.index, result[col], color=color, alpha=0.8, legend_label=col)\n",
    "        p_list.append(p)\n",
    "    grid = gridplot([[x] for x in p_list], sizing_mode='scale_width', plot_height=50)\n",
    "    show(grid)\n",
    "    result = result.sort_values(by=['RawScore'], ascending=False)\n",
    "    top_anomaly = list(result[result.isAnomaly].index.strftime('%Y-%m-%dT%H:%M:%SZ'))[0]\n",
    "    print(\"Top Anomaly Timestamp is : {0}\".format(top_anomaly))\n",
    "    return series, raw_result, top_anomaly\n",
    "\n",
    "def show_contribution(series, raw_result, anomaly_timestamp):\n",
    "    anomaly_result = [x for x in raw_result['results'] if 'contributors' in x['value'] and x['timestamp'] == top_anomaly][0]\n",
    "    contributors = [x['variable'] for x in anomaly_result['value']['contributors']]\n",
    "    series_index = pd.DataFrame({'index': list(range(0, len(series))), 'name': [x.columns[0] for x in series]})\n",
    "    series_index = series_index.set_index('name')\n",
    "    sorted_series = [series[i][series[i].index <= top_anomaly].tail(SLIDING_WINDOW) for i in series_index.reindex(contributors)['index'].values]\n",
    "    p_list = []\n",
    "    colors = itertools.cycle(palette)\n",
    "    for var, color in zip(sorted_series, colors):\n",
    "        name = var.columns.values[0]\n",
    "        p_value = figure(background_fill_color=\"#fafafa\", x_axis_type=\"datetime\")\n",
    "        plot_lines_multi(var.index, var[name], p_value, color, name)\n",
    "        p_list.append(p_value)\n",
    "    grid = gridplot([[x] for x in p_list], sizing_mode='scale_width', plot_height=50)\n",
    "    show(grid)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"20472\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"20472\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"20472\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "data_source = SOURCE_BLOB_SAS\n",
    "local_data_path = r\"C:\\Users\\a0730244\\Documents\\DATAPERMINUTE.zip\"\n",
    "severity = 0.7\n",
    "start_date = \"2020-08-25T00:00:00Z\"\n",
    "end_date = \"2020-08-26T00:00:00Z\"\n",
    "#'startTime': '2020-08-25T00:00:00Z', \n",
    "#'endTime': '2020-09-28T00:00:00Z', \n",
    "series, raw_result, top_anomaly = draw(data_source, local_data_path, result_id, severity, start_date, end_date)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C:\\Users\\a0730244\\Documents\\DATAPERMINUTE.zip 27932f10-bd24-11eb-a16f-faed18866e16 0.7 2020-08-25T00:00:00Z 2020-08-26T00:00:00Z\n",
      "<zipfile.ZipFile filename='C:\\\\Users\\\\a0730244\\\\Documents\\\\DATAPERMINUTE.zip' mode='r'>\n",
      "result not ready\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-30c5dc00d400>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#'startTime': '2020-08-25T00:00:00Z',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#'endTime': '2020-09-28T00:00:00Z',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_anomaly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseverity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "show_contribution(series, raw_result, top_anomaly)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export model by modelid\n",
    "```http\n",
    "[GET] https://{endpoint}/multivariate/models/{model_id}/export\n",
    "```\n",
    "you can take the model zip file to other env to do inference.\n",
    "#### Sample\n",
    " - Request\n",
    "```json\n",
    "header ={\"Content-Type\": \"application/json\", \"Ocp-Apim-Subscription-Key\": \"subscription_key\"}\n",
    "```\n",
    " - Response\n",
    "```json\n",
    "zip file\n",
    "```\n",
    " - Error Response\n",
    " ```json\n",
    "{\n",
    "\"code\": \"string\",\n",
    "\"message\": \"string\"\n",
    "}\n",
    " ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res = requests.get(API_EXPORT.format(endpoint=ENDPOINT, model_id=model_id), headers=HEADERS)\n",
    "assert res.status_code == 200, f\"Error occured. Error message: {res.content}\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Delete model by modelid\n",
    "```http\n",
    "[DELETE] https://{endpoint}/multivariate/models/{model_id}\n",
    "```\n",
    "#### Sample\n",
    " - Request\n",
    "```json\n",
    "header ={\"Content-Type\": \"application/json\", \"Ocp-Apim-Subscription-Key\": \"subscription_key\"}\n",
    "```\n",
    " - Response\n",
    "```json\n",
    "response={}\n",
    "```\n",
    " - Error Response\n",
    " ```json\n",
    "{\n",
    "\"code\": \"string\",\n",
    "\"message\": \"string\"\n",
    "}\n",
    " ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res = requests.delete(API_DELETE.format(endpoint=ENDPOINT, model_id=model_id), headers=HEADERS)\n",
    "assert res.status_code == 204, f\"Error occured. Error message: {res.content}\"\n",
    "print(res.content)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model list has been updated."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res = requests.get(API_MODEL.format(endpoint=ENDPOINT), headers=HEADERS)\n",
    "assert res.status_code == 200, f\"Error occured. Error message: {res.content}\"\n",
    "print(res.content)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}